{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640a234-aeda-47d1-9d31-3b0f14dd9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ORCID 女性姓名变化检测程序\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool, Manager, Lock\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import signal\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "# 全局配置\n",
    "CONFIG = {\n",
    "    'base_path': '/hy-tmp/ORCID_2024_10_summaries',\n",
    "    'output_file': '/hy-tmp/female_name_changes.csv',\n",
    "    'log_file': '/hy-tmp/orcid_processing.log',\n",
    "    'max_workers': 20,  # 保留2个核心给系统\n",
    "    'chunk_size': 1000,  # 每个进程处理的文件数量\n",
    "    'batch_size': 100,  # 批量写入CSV的记录数\n",
    "}\n",
    "\n",
    "class ORCIDProcessor:\n",
    "    def __init__(self, base_path: str, output_file: str, max_workers: int = 38):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.output_file = output_file\n",
    "        self.max_workers = max_workers\n",
    "        self.gender_detector = gender.Detector()\n",
    "        self.setup_logging()\n",
    "        \n",
    "        # 统计信息\n",
    "        self.stats = {\n",
    "            'total_files': 0,\n",
    "            'processed_files': 0,\n",
    "            'female_records': 0,\n",
    "            'name_changes': 0,\n",
    "            'errors': 0\n",
    "        }\n",
    "\n",
    "    def setup_logging(self):\n",
    "        \"\"\"配置日志系统\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(CONFIG['log_file']),\n",
    "                logging.StreamHandler(sys.stdout)\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def extract_name_info(self, soup: BeautifulSoup) -> Optional[Dict]:\n",
    "        \"\"\"从BeautifulSoup对象中提取姓名信息和性别\"\"\"\n",
    "        try:\n",
    "            person_name_tag = soup.find(\"person:name\")\n",
    "            if not person_name_tag:\n",
    "                return None\n",
    "\n",
    "            # 提取person:name基本信息\n",
    "            person_created_date_tag = person_name_tag.find(\"common:created-date\")\n",
    "            given_names_tag = person_name_tag.find(\"personal-details:given-names\")\n",
    "            family_name_tag = person_name_tag.find(\"personal-details:family-name\")\n",
    "\n",
    "            person_created_date = person_created_date_tag.string if person_created_date_tag else None\n",
    "            given_name = given_names_tag.string if given_names_tag else None\n",
    "            family_name = family_name_tag.string if family_name_tag else None\n",
    "\n",
    "            # 性别识别 - 只处理女性\n",
    "            if not given_name:\n",
    "                return None\n",
    "            \n",
    "            gender_result = self.gender_detector.get_gender(given_name.split()[0])\n",
    "            if gender_result not in ['female', 'mostly_female']:\n",
    "                return None  # 只处理女性\n",
    "\n",
    "            # 构建基准姓名 (given_name + family_name)\n",
    "            if not family_name:\n",
    "                return None\n",
    "            base_name = f\"{given_name} {family_name}\".strip()\n",
    "\n",
    "            # 提取other-name信息 - 可能有多个\n",
    "            other_names_data = []\n",
    "            other_name_tags = soup.find_all(\"other-name:other-name\")\n",
    "            \n",
    "            for other_name_tag in other_name_tags:\n",
    "                other_created_date_tag = other_name_tag.find(\"common:created-date\")\n",
    "                other_name_content_tag = other_name_tag.find(\"other-name:content\")\n",
    "                \n",
    "                other_created_date = other_created_date_tag.string if other_created_date_tag else None\n",
    "                other_name_content = other_name_content_tag.string if other_name_content_tag else None\n",
    "                \n",
    "                if other_created_date and other_name_content:\n",
    "                    other_names_data.append({\n",
    "                        'other_name_content': other_name_content,\n",
    "                        'other_created_date': other_created_date\n",
    "                    })\n",
    "\n",
    "            if not other_names_data:\n",
    "                return None\n",
    "\n",
    "            return {\n",
    "                'person_created_date': person_created_date,\n",
    "                'given_name': given_name,\n",
    "                'family_name': family_name,\n",
    "                'base_name': base_name,\n",
    "                'other_names_data': other_names_data,\n",
    "                'gender': gender_result\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.debug(f\"Error extracting name info: {e}\")\n",
    "            return None\n",
    "\n",
    "    def is_name_change_candidate(self, name_info: Dict) -> Tuple[bool, Optional[List]]:\n",
    "        \"\"\"判断是否为姓名变化候选者\"\"\"\n",
    "        try:\n",
    "            from datetime import datetime, timedelta\n",
    "            \n",
    "            base_name = name_info['base_name']  # given_name + family_name\n",
    "            person_created_date = name_info['person_created_date']\n",
    "            other_names_data = name_info['other_names_data']\n",
    "            family_name = name_info['family_name']\n",
    "            given_name = name_info['given_name']\n",
    "\n",
    "            if not all([base_name, person_created_date, other_names_data, family_name, given_name]):\n",
    "                return False, None\n",
    "\n",
    "            # 解析person:name的创建日期\n",
    "            try:\n",
    "                person_date = datetime.fromisoformat(person_created_date.replace('Z', '+00:00'))\n",
    "            except:\n",
    "                return False, None\n",
    "\n",
    "            # 检查每个other-name\n",
    "            for other_data in other_names_data:\n",
    "                other_name_content = other_data['other_name_content']\n",
    "                other_created_date = other_data['other_created_date']\n",
    "                \n",
    "                if not other_name_content or not other_created_date:\n",
    "                    continue\n",
    "\n",
    "                # 检查other-name中是否包含原始的姓氏或名字（关联性验证）\n",
    "                if not (str(family_name).lower() in str(other_name_content).lower() or \n",
    "                       str(given_name).lower() in str(other_name_content).lower()):\n",
    "                    continue\n",
    "\n",
    "                # 解析other-name的创建日期\n",
    "                try:\n",
    "                    other_date = datetime.fromisoformat(other_created_date.replace('Z', '+00:00'))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                # 检查时间差是否超过30天\n",
    "                time_diff = abs((person_date - other_date).days)\n",
    "                if time_diff < 30:\n",
    "                    continue\n",
    "\n",
    "                # 标准化姓名\n",
    "                cleaned_base_name = str(base_name).strip().lower().replace('-', ' ').replace('.', '')\n",
    "                cleaned_other_name = str(other_name_content).strip().lower().replace('-', ' ').replace('.', '')\n",
    "\n",
    "                # 排除完全相同的姓名\n",
    "                if cleaned_base_name.replace(' ', '') == cleaned_other_name.replace(' ', ''):\n",
    "                    continue\n",
    "\n",
    "                # 检查名字部分是否相同（确保是同一人）\n",
    "                base_parts = cleaned_base_name.split(' ')\n",
    "                other_parts = cleaned_other_name.split(' ')\n",
    "                \n",
    "                if len(base_parts) == 0 or len(other_parts) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # 名字（first name）必须相同\n",
    "                if base_parts[0] != other_parts[0]:\n",
    "                    continue\n",
    "\n",
    "                # 分析姓名变化模式\n",
    "                base_surnames = base_parts[1:]  # 姓氏部分\n",
    "                other_surnames = other_parts[1:]  # 姓氏部分\n",
    "                \n",
    "                if len(base_surnames) == 0 or len(other_surnames) == 0:\n",
    "                    continue\n",
    "\n",
    "                # 检查是否有共同姓氏\n",
    "                common_surnames = set(base_surnames) & set(other_surnames)\n",
    "                \n",
    "                if len(common_surnames) > 0:\n",
    "                    # 情况1：加中间名（有共同姓氏）\n",
    "                    # 检查一个是另一个的子集\n",
    "                    if (set(base_surnames).issubset(set(other_surnames)) and len(base_surnames) < len(other_surnames)) or \\\n",
    "                       (set(other_surnames).issubset(set(base_surnames)) and len(other_surnames) < len(base_surnames)):\n",
    "                        \n",
    "                        # 确定哪个是较早的日期\n",
    "                        if person_date < other_date:\n",
    "                            earlier_name = cleaned_base_name\n",
    "                            earlier_date = person_created_date\n",
    "                            later_name = cleaned_other_name\n",
    "                            later_date = other_created_date\n",
    "                        else:\n",
    "                            earlier_name = cleaned_other_name\n",
    "                            earlier_date = other_created_date\n",
    "                            later_name = cleaned_base_name\n",
    "                            later_date = person_created_date\n",
    "                        \n",
    "                        return True, [earlier_name, earlier_date, later_name, later_date]\n",
    "                else:\n",
    "                    # 情况2：改姓（无共同姓氏）\n",
    "                    # 排除缩写情况\n",
    "                    if len(base_surnames) == 1 and len(other_surnames) == 1:\n",
    "                        if (len(base_surnames[0]) == 1 or len(other_surnames[0]) == 1) and \\\n",
    "                           base_surnames[0][0] == other_surnames[0][0]:\n",
    "                            continue  # 跳过缩写情况\n",
    "                        \n",
    "                        return True, [cleaned_base_name, person_created_date, cleaned_other_name, other_created_date]\n",
    "\n",
    "            return False, None\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.debug(f\"Error in name change detection: {e}\")\n",
    "            return False, None\n",
    "\n",
    "    def process_single_file(self, file_path: Path, port_name: str) -> Optional[Dict]:\n",
    "        \"\"\"处理单个XML文件\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                soup = BeautifulSoup(file, 'xml')\n",
    "                name_info = self.extract_name_info(soup)\n",
    "\n",
    "                if not name_info:\n",
    "                    return None\n",
    "\n",
    "                is_change, change_data = self.is_name_change_candidate(name_info)\n",
    "                if is_change and change_data:\n",
    "                    path_tag = soup.find(\"common:path\")\n",
    "                    orcid_id = path_tag.string if path_tag else \"unknown\"\n",
    "                    \n",
    "                    return {\n",
    "                        'port_name': port_name,\n",
    "                        'id': orcid_id,\n",
    "                        'person_name': change_data[0],\n",
    "                        'person_date': change_data[1],\n",
    "                        'other_name': change_data[2],\n",
    "                        'other_date': change_data[3],\n",
    "                        'gender': name_info['gender']\n",
    "                    }\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.debug(f\"Error processing file {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "def process_file_chunk(args):\n",
    "    \"\"\"处理文件块的工作函数\"\"\"\n",
    "    file_paths, port_name, process_id = args\n",
    "    processor = ORCIDProcessor(CONFIG['base_path'], CONFIG['output_file'])\n",
    "    results = []\n",
    "    processed = 0\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            result = processor.process_single_file(file_path, port_name)\n",
    "            if result:\n",
    "                results.append(result)\n",
    "            processed += 1\n",
    "            \n",
    "            # 每处理1000000个文件报告一次进度\n",
    "            if processed % 1000000 == 0:\n",
    "                print(f\"Process {process_id}: Processed {processed}/{len(file_paths)} files in {port_name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in process {process_id} processing {file_path}: {e}\")\n",
    "    \n",
    "    return results, processed, len(results)\n",
    "\n",
    "def get_file_chunks(base_path: str, chunk_size: int = 1000) -> List[Tuple]:\n",
    "    \"\"\"获取文件分块信息\"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "    \n",
    "    for portfolio_folder in base_path.iterdir():\n",
    "        if not portfolio_folder.is_dir():\n",
    "            continue\n",
    "            \n",
    "        # 获取文件夹中的所有XML文件\n",
    "        xml_files = list(portfolio_folder.glob(\"*.xml\"))\n",
    "        if not xml_files:\n",
    "            xml_files = list(portfolio_folder.iterdir())  # 如果没有.xml扩展名\n",
    "            \n",
    "        # 将文件分块\n",
    "        for i in range(0, len(xml_files), chunk_size):\n",
    "            file_chunk = xml_files[i:i + chunk_size]\n",
    "            chunks.append((file_chunk, portfolio_folder.name, chunk_id))\n",
    "            chunk_id += 1\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def write_results_batch(results_batch: List[Dict], output_file: str, write_header: bool = False):\n",
    "    \"\"\"批量写入结果到CSV文件\"\"\"\n",
    "    mode = 'w' if write_header else 'a'\n",
    "    with open(output_file, mode, newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['port_name', 'id', 'person_name', 'person_date', \n",
    "                                             'other_name', 'other_date', 'gender'])\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        writer.writerows(results_batch)\n",
    "\n",
    "def signal_handler(signum, frame):\n",
    "    \"\"\"信号处理器\"\"\"\n",
    "    print(\"\\n收到中断信号，正在安全退出...\")\n",
    "    sys.exit(0)\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 注册信号处理器\n",
    "    signal.signal(signal.SIGINT, signal_handler)\n",
    "    signal.signal(signal.SIGTERM, signal_handler)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 获取文件分块\n",
    "    print(\"正在分析文件结构...\")\n",
    "    chunks = get_file_chunks(CONFIG['base_path'], CONFIG['chunk_size'])\n",
    "    total_chunks = len(chunks)\n",
    "    \n",
    "    print(f\"发现 {total_chunks} 个文件块\")\n",
    "    if total_chunks == 0:\n",
    "        print(\"没有找到需要处理的文件\")\n",
    "        return\n",
    "    \n",
    "    # 初始化输出文件\n",
    "    write_results_batch([], CONFIG['output_file'], write_header=True)\n",
    "    \n",
    "    # 统计变量\n",
    "    total_processed = 0\n",
    "    total_results = 0\n",
    "    results_buffer = []\n",
    "    \n",
    "    try:\n",
    "        # 使用进程池处理\n",
    "        with ProcessPoolExecutor(max_workers=CONFIG['max_workers']) as executor:\n",
    "            print(f\"启动 {CONFIG['max_workers']} 个工作进程...\")\n",
    "            \n",
    "            # 提交所有任务\n",
    "            future_to_chunk = {executor.submit(process_file_chunk, chunk): i \n",
    "                              for i, chunk in enumerate(chunks)}\n",
    "            \n",
    "            # 处理完成的任务\n",
    "            for future in as_completed(future_to_chunk):\n",
    "                chunk_idx = future_to_chunk[future]\n",
    "                try:\n",
    "                    chunk_results, chunk_processed, chunk_found = future.result()\n",
    "                    \n",
    "                    total_processed += chunk_processed\n",
    "                    total_results += chunk_found\n",
    "                    results_buffer.extend(chunk_results)\n",
    "                    \n",
    "                    # 批量写入结果\n",
    "                    if len(results_buffer) >= CONFIG['batch_size']:\n",
    "                        write_results_batch(results_buffer, CONFIG['output_file'])\n",
    "                        results_buffer = []\n",
    "                    \n",
    "                    # 进度报告\n",
    "                    progress = (chunk_idx + 1) / total_chunks * 100\n",
    "                    print(f\"进度: {progress:.1f}% ({chunk_idx + 1}/{total_chunks}), \"\n",
    "                          f\"已处理: {total_processed:,}, 发现变化: {total_results:,}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"处理块 {chunk_idx} 时出错: {e}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n用户中断程序执行\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"程序执行出错: {e}\")\n",
    "        return\n",
    "    finally:\n",
    "        # 写入剩余结果\n",
    "        if results_buffer:\n",
    "            write_results_batch(results_buffer, CONFIG['output_file'])\n",
    "    \n",
    "    # 最终统计\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"处理完成!\")\n",
    "    print(f\"总处理文件数: {total_processed:,}\")\n",
    "    print(f\"发现姓名变化: {total_results:,}\")\n",
    "    print(f\"处理时间: {duration/3600:.1f} 小时 ({duration/60:.1f} 分钟)\")\n",
    "    print(f\"平均速度: {total_processed/duration:.0f} 文件/秒\")\n",
    "    print(f\"结果已保存至: {CONFIG['output_file']}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
