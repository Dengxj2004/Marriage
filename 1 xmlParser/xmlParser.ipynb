{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640a234-aeda-47d1-9d31-3b0f14dd9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "ORCID 女性姓名变化检测程序\n",
    "\"\"\"\n",
    "import os\n",
    "import csv\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool, Manager, Lock\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import signal\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "# 全局配置\n",
    "CONFIG = {\n",
    "    'base_path': '/hy-tmp/ORCID_2024_10_summaries',\n",
    "    'output_file': '/hy-tmp/female_name_changes.csv',\n",
    "    'log_file': '/hy-tmp/orcid_processing.log',\n",
    "    'max_workers': 20,  \n",
    "    'chunk_size': 1000,  # 每个进程处理的文件数量\n",
    "    'batch_size': 100,  # 批量写入CSV的记录数\n",
    "}\n",
    "\n",
    "class ORCIDProcessor:\n",
    "    def __init__(self, base_path: str, output_file: str, max_workers: int = 38):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.output_file = output_file\n",
    "        self.max_workers = max_workers\n",
    "        self.gender_detector = gender.Detector()\n",
    "        self.setup_logging()\n",
    "        \n",
    "        # 统计信息\n",
    "        self.stats = {\n",
    "            'total_files': 0,\n",
    "            'processed_files': 0,\n",
    "            'female_records': 0,\n",
    "            'name_changes': 0,\n",
    "            'errors': 0\n",
    "        }\n",
    "\n",
    "    def setup_logging(self):\n",
    "        \"\"\"配置日志系统\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(CONFIG['log_file']),\n",
    "                logging.StreamHandler(sys.stdout)\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def extract_name_info(self, soup: BeautifulSoup) -> Optional[Dict]:\n",
    "        \"\"\"从BeautifulSoup对象中提取姓名信息和性别\"\"\"\n",
    "        try:\n",
    "            person_name_tag = soup.find(\"person:name\")\n",
    "            if not person_name_tag:\n",
    "                return None\n",
    "\n",
    "            # 提取基本信息\n",
    "            first_date_tag = person_name_tag.find(\"common:last-modified-date\")\n",
    "            given_names_tag = person_name_tag.find(\"personal-details:given-names\")\n",
    "            family_name_tag = person_name_tag.find(\"personal-details:family-name\")\n",
    "            other_name_tag_wrapper = soup.find(\"other-name:other-name\")\n",
    "\n",
    "            first_date = first_date_tag.string if first_date_tag else None\n",
    "            given_name = given_names_tag.string if given_names_tag else None\n",
    "            family_name = family_name_tag.string if family_name_tag else None\n",
    "\n",
    "            # 性别识别 - 只处理女性\n",
    "            if not given_name:\n",
    "                return None\n",
    "            \n",
    "            gender_result = self.gender_detector.get_gender(given_name.split()[0])\n",
    "            if gender_result not in ['female', 'mostly_female']:\n",
    "                return None  # 只处理女性\n",
    "\n",
    "            # 提取其他姓名信息\n",
    "            if not other_name_tag_wrapper:\n",
    "                return None\n",
    "\n",
    "            source_name_tag = other_name_tag_wrapper.find(\"common:source-name\")\n",
    "            other_name_content_tag = other_name_tag_wrapper.find(\"other-name:content\")\n",
    "            last_modified_date_tag = other_name_tag_wrapper.find(\"common:last-modified-date\")\n",
    "\n",
    "            source_name = source_name_tag.string if source_name_tag else None\n",
    "            other_name_content = other_name_content_tag.string if other_name_content_tag else None\n",
    "            last_modified_date_other_name = last_modified_date_tag.string if last_modified_date_tag else None\n",
    "\n",
    "            return {\n",
    "                'first_date': first_date,\n",
    "                'given_name': given_name,\n",
    "                'family_name': family_name,\n",
    "                'source_name': source_name,\n",
    "                'other_name_content': other_name_content,\n",
    "                'last_modified_date_other_name': last_modified_date_other_name,\n",
    "                'gender': gender_result\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.debug(f\"Error extracting name info: {e}\")\n",
    "            return None\n",
    "\n",
    "    def is_name_change_candidate(self, name_info: Dict) -> Tuple[bool, Optional[List]]:\n",
    "        \"\"\"判断是否为姓名变化候选者\"\"\"\n",
    "        try:\n",
    "            source_name = name_info['source_name']\n",
    "            other_name_content = name_info['other_name_content']\n",
    "            family_name = name_info['family_name']\n",
    "            given_name = name_info['given_name']\n",
    "            first_date = name_info['first_date']\n",
    "            last_modified_date_other_name = name_info['last_modified_date_other_name']\n",
    "\n",
    "            if not all([source_name, other_name_content, family_name, given_name, \n",
    "                       first_date, last_modified_date_other_name]):\n",
    "                return False, None\n",
    "\n",
    "            # 检查姓名中是否包含family_name或given_name\n",
    "            if not (str(family_name).lower() in str(other_name_content).lower() or \n",
    "                   str(given_name).lower() in str(other_name_content).lower()):\n",
    "                return False, None\n",
    "\n",
    "            # 标准化姓名\n",
    "            cleaned_source_name = str(source_name).strip().lower().replace('-', ' ').replace('.', '')\n",
    "            cleaned_other_name_content = str(other_name_content).strip().lower().replace('-', ' ').replace('.', '')\n",
    "\n",
    "            # 基本条件检查\n",
    "            if (cleaned_source_name.replace(' ', '') == cleaned_other_name_content.replace(' ', '') or\n",
    "                cleaned_source_name.split(' ')[0] != cleaned_other_name_content.split(' ')[0] or\n",
    "                first_date[0:10] == last_modified_date_other_name[0:10]):\n",
    "                return False, None\n",
    "\n",
    "            # 检查是否为姓名变化（加中间名或改姓）\n",
    "            source_parts = cleaned_source_name.split(' ')\n",
    "            other_parts = cleaned_other_name_content.split(' ')\n",
    "            common_surnames = set(source_parts[1:]) & set(other_parts[1:])\n",
    "\n",
    "            if len(common_surnames) > 0:\n",
    "                # 可能是加中间名的情况\n",
    "                if ((len(cleaned_source_name) > len(cleaned_other_name_content) and \n",
    "                     first_date[0:10] > last_modified_date_other_name[0:10]) or\n",
    "                    (len(cleaned_other_name_content) > len(cleaned_source_name) and \n",
    "                     last_modified_date_other_name[0:10] > first_date[0:10])):\n",
    "                    \n",
    "                    if (source_parts == other_parts[:-1] or other_parts == source_parts[:-1]):\n",
    "                        return True, [cleaned_source_name, first_date, \n",
    "                                    cleaned_other_name_content, last_modified_date_other_name]\n",
    "            else:\n",
    "                # 可能是改姓的情况\n",
    "                if len(source_parts) >= 2 and len(other_parts) >= 2:\n",
    "                    if not (len(source_parts) == 2 and \n",
    "                           (len(source_parts[1]) == 1 or len(other_parts[1]) == 1) and \n",
    "                           source_parts[1][0] == other_parts[1][0]):\n",
    "                        return True, [cleaned_source_name, first_date, \n",
    "                                    cleaned_other_name_content, last_modified_date_other_name]\n",
    "\n",
    "            return False, None\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.debug(f\"Error in name change detection: {e}\")\n",
    "            return False, None\n",
    "\n",
    "    def process_single_file(self, file_path: Path, port_name: str) -> Optional[Dict]:\n",
    "        \"\"\"处理单个XML文件\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                soup = BeautifulSoup(file, 'xml')\n",
    "                name_info = self.extract_name_info(soup)\n",
    "\n",
    "                if not name_info:\n",
    "                    return None\n",
    "\n",
    "                is_change, change_data = self.is_name_change_candidate(name_info)\n",
    "                if is_change and change_data:\n",
    "                    path_tag = soup.find(\"common:path\")\n",
    "                    orcid_id = path_tag.string if path_tag else \"unknown\"\n",
    "                    \n",
    "                    return {\n",
    "                        'port_name': port_name,\n",
    "                        'id': orcid_id,\n",
    "                        's_name': change_data[0],\n",
    "                        'first_date': change_data[1],\n",
    "                        'o_name': change_data[2],\n",
    "                        'last_modified_date': change_data[3],\n",
    "                        'gender': name_info['gender']\n",
    "                    }\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.debug(f\"Error processing file {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "def process_file_chunk(args):\n",
    "    \"\"\"处理文件块的工作函数\"\"\"\n",
    "    file_paths, port_name, process_id = args\n",
    "    processor = ORCIDProcessor(CONFIG['base_path'], CONFIG['output_file'])\n",
    "    results = []\n",
    "    processed = 0\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            result = processor.process_single_file(file_path, port_name)\n",
    "            if result:\n",
    "                results.append(result)\n",
    "            processed += 1\n",
    "            \n",
    "            # 每处理100000个文件报告一次进度\n",
    "            if processed % 100000 == 0:\n",
    "                print(f\"Process {process_id}: Processed {processed}/{len(file_paths)} files in {port_name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in process {process_id} processing {file_path}: {e}\")\n",
    "    \n",
    "    return results, processed, len(results)\n",
    "\n",
    "def get_file_chunks(base_path: str, chunk_size: int = 1000) -> List[Tuple]:\n",
    "    \"\"\"获取文件分块信息\"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "    \n",
    "    for portfolio_folder in base_path.iterdir():\n",
    "        if not portfolio_folder.is_dir():\n",
    "            continue\n",
    "            \n",
    "        # 获取文件夹中的所有XML文件\n",
    "        xml_files = list(portfolio_folder.glob(\"*.xml\"))\n",
    "        if not xml_files:\n",
    "            xml_files = list(portfolio_folder.iterdir())  # 如果没有.xml扩展名\n",
    "            \n",
    "        # 将文件分块\n",
    "        for i in range(0, len(xml_files), chunk_size):\n",
    "            file_chunk = xml_files[i:i + chunk_size]\n",
    "            chunks.append((file_chunk, portfolio_folder.name, chunk_id))\n",
    "            chunk_id += 1\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def write_results_batch(results_batch: List[Dict], output_file: str, write_header: bool = False):\n",
    "    \"\"\"批量写入结果到CSV文件\"\"\"\n",
    "    mode = 'w' if write_header else 'a'\n",
    "    with open(output_file, mode, newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['port_name', 'id', 's_name', 'first_date', \n",
    "                                             'o_name', 'last_modified_date', 'gender'])\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        writer.writerows(results_batch)\n",
    "\n",
    "def signal_handler(signum, frame):\n",
    "    \"\"\"信号处理器\"\"\"\n",
    "    print(\"\\n收到中断信号，正在安全退出...\")\n",
    "    sys.exit(0)\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 注册信号处理器\n",
    "    signal.signal(signal.SIGINT, signal_handler)\n",
    "    signal.signal(signal.SIGTERM, signal_handler)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # 获取文件分块\n",
    "    chunks = get_file_chunks(CONFIG['base_path'], CONFIG['chunk_size'])\n",
    "    total_chunks = len(chunks)\n",
    "    \n",
    "    print(f\"发现 {total_chunks} 个文件块\")\n",
    "    if total_chunks == 0:\n",
    "        print(\"没有找到需要处理的文件\")\n",
    "        return\n",
    "    \n",
    "    # 初始化输出文件\n",
    "    write_results_batch([], CONFIG['output_file'], write_header=True)\n",
    "    \n",
    "    # 统计变量\n",
    "    total_processed = 0\n",
    "    total_results = 0\n",
    "    results_buffer = []\n",
    "    \n",
    "    try:\n",
    "        # 使用进程池处理\n",
    "        with ProcessPoolExecutor(max_workers=CONFIG['max_workers']) as executor:\n",
    "            print(f\"启动 {CONFIG['max_workers']} 个工作进程...\")\n",
    "            \n",
    "            # 提交所有任务\n",
    "            future_to_chunk = {executor.submit(process_file_chunk, chunk): i \n",
    "                              for i, chunk in enumerate(chunks)}\n",
    "            \n",
    "            # 处理完成的任务\n",
    "            for future in as_completed(future_to_chunk):\n",
    "                chunk_idx = future_to_chunk[future]\n",
    "                try:\n",
    "                    chunk_results, chunk_processed, chunk_found = future.result()\n",
    "                    \n",
    "                    total_processed += chunk_processed\n",
    "                    total_results += chunk_found\n",
    "                    results_buffer.extend(chunk_results)\n",
    "                    \n",
    "                    # 批量写入结果\n",
    "                    if len(results_buffer) >= CONFIG['batch_size']:\n",
    "                        write_results_batch(results_buffer, CONFIG['output_file'])\n",
    "                        results_buffer = []\n",
    "                    \n",
    "                    # 进度报告\n",
    "                    progress = (chunk_idx + 1) / total_chunks * 100\n",
    "                    print(f\"进度: {progress:.1f}% ({chunk_idx + 1}/{total_chunks}), \"\n",
    "                          f\"已处理: {total_processed:,}, 发现变化: {total_results:,}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"处理块 {chunk_idx} 时出错: {e}\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n用户中断程序执行\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"程序执行出错: {e}\")\n",
    "        return\n",
    "    finally:\n",
    "        # 写入剩余结果\n",
    "        if results_buffer:\n",
    "            write_results_batch(results_buffer, CONFIG['output_file'])\n",
    "    \n",
    "    # 最终统计\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"处理完成!\")\n",
    "    print(f\"总处理文件数: {total_processed:,}\")\n",
    "    print(f\"发现姓名变化: {total_results:,}\")\n",
    "    print(f\"处理时间: {duration/3600:.1f} 小时 ({duration/60:.1f} 分钟)\")\n",
    "    print(f\"平均速度: {total_processed/duration:.0f} 文件/秒\")\n",
    "    print(f\"结果已保存至: {CONFIG['output_file']}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
